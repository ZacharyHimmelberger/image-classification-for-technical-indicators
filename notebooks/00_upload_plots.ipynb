{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/image-classification-for-technical-indicators\n"
     ]
    }
   ],
   "source": [
    "%pwd  \n",
    "%cd /workspaces/image-classification-for-technical-indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this script, we will walk through the entire project. This script will result in plots uploaded in an AWS s3 bucket. \n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import aws\n",
    "from source import features\n",
    "from source import plots\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import alpaca_trade_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Raw Data\n",
    "\n",
    "The data consists of 8 years (1 January 2011 - 1 January 2019) of open, high, low, and close data for 505 tickers. All data comes from Alpaca Inc. (https://alpaca.markets/algotrading).\n",
    "\n",
    "We connected to the Amazon AWS Secret Manager to obtain the Alpaca API log-in information. Then, we iterated through the list of S&P 500 firms in the data/list_of_SP_500.csv file and obtained the data from the Alpaca API for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name = \"AlpacaAPI\"\n",
    "region_name = \"us-east-2\"\n",
    "\n",
    "session = boto3.session.Session()\n",
    "client = session.client(\n",
    "    service_name='secretsmanager',\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "secret = json.loads(get_secret_value_response['SecretString'])\n",
    "\n",
    "api_key = secret[\"api_key\"]\n",
    "api_secret = secret[\"api_secret\"]\n",
    "base_url = \"https://api.alpaca.markets\"\n",
    "api = alpaca_trade_api.REST(api_key, api_secret, base_url, api_version='v2')\n",
    "account = api.get_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_500_df = pd.read_csv('data/list_of_SP_500.csv', header=None, names=['symbol', 'name'])\n",
    "SP_500 = SP_500_df[\"symbol\"].tolist()\n",
    "\n",
    "list_of_dataframes = []\n",
    "\n",
    "start_dates = ['2011-01-01 09:30', '2014-01-02 09:30', '2017-01-02 09:30']\n",
    "end_dates = ['2014-01-01 09:30', '2017-01-01 09:30', '2019-01-01 09:30']\n",
    "\n",
    "for firm in SP_500:\n",
    "    time.sleep(1) # ensures we don't hit any API limits   \n",
    "    for idx in range(len(start_dates)):\n",
    "        get_data = api.get_barset(symbols=firm, timeframe=\"day\", start=pd.Timestamp(start_dates[idx],tz='America/New_York').isoformat(), \\\n",
    "            end=pd.Timestamp(end_dates[idx],tz='America/New_York').isoformat(), limit=1000).df.stack(level=0)\n",
    "        list_of_dataframes.append(get_data)\n",
    "\n",
    "df = pd.concat(list_of_dataframes)\n",
    "df.index.names = ['time','firm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features\n",
    "\n",
    "We compute three technical indicators: (moving average convergence/divergence)[https://en.wikipedia.org/wiki/MACD] (MACD), (relative strength index)[https://en.wikipedia.org/wiki/Relative_strength_index] (RSI), and (Bollinger Bands)[https://en.wikipedia.org/wiki/Bollinger_Bands] (BB). The MACD is measured over 26 days, RSI over 27 days, and BB over 20 days. A buy signal is triggered when:\n",
    "\n",
    "**MACD:** the MACD crosses above the MACD signal line.\n",
    "\n",
    "**RSI:** the RSI crosses above 30. \n",
    "\n",
    "**BB:** the close value crosses below the lower band.\n",
    "\n",
    "We obtained the technical indicator values, then created a column in the DataFrame to indicate when a buy signal was triggered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rsi'] = features.build_indicator(df, \"rsi\", 27)\n",
    "df['rsi_buy'] = features.rsi_buy_indicator(df['rsi'])\n",
    "\n",
    "df['bb_lower_band'] = features.build_indicator(df, \"bbands\", 20)['BBL_20_2.0']\n",
    "df['bb_buy'] = features.bb_buy_indicator(bb_lower_band_col=df['bb_lower_band'], close_col=df['close'])\n",
    "\n",
    "df['macd_signal'] = features.build_indicator(df, \"macd\", 26)['MACDs_12_26_9']\n",
    "df['macd'] = features.build_indicator(df, \"macd\", 26)['MACD_12_26_9']\n",
    "df['macd_buy'] = features.macd_buy_indicator(macd_signal_col=df['macd_signal'], macd_col=df['macd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/historical_data_added_features.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked to make sure that we had at least 20 buy indicators to sample from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_few_rsi = [(firm, data['rsi_buy'].sum()) for firm, data in df.groupby('firm') if (data['rsi_buy'].sum() < 20)]\n",
    "too_few_bb = [(firm, data['bb_buy'].sum()) for firm, data in df.groupby('firm') if (data['bb_buy'].sum() < 20)]\n",
    "too_few_macd = [(firm, data['macd_buy'].sum()) for firm, data in df.groupby('firm') if (data['macd_buy'].sum() < 20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{round(len(too_few_rsi) / len(df.groupby(\"firm\")) * 100, 2)}% of firms have fewer than 20 RSI buy signals.')\n",
    "print(f'{round(len(too_few_bb) / len(df.groupby(\"firm\")) * 100, 2)}% of firms have fewer than 20 BB buy signals.')\n",
    "print(f'{round(len(too_few_macd) / len(df.groupby(\"firm\")) * 100, 2)}% of firms have fewer than 20 MACD buy signals.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because none of the firms have at least 20 RSI buy signals, we will exclude that technical indicator from all future analyses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create AWS s3 Bucket\n",
    "\n",
    "We created an AWS s3 Bucket to send the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"line-candle-ohlc-plot\"\n",
    "\n",
    "aws.create_bucket(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plots\n",
    "\n",
    "We randomly sampled 20 buy signals and 20 non-buy signals per firm for the BB and MACD technical indicators. This resulted in [505 firms X 2 indicators X 40 (20 buy signals + 20 non-buy signals) = 40400] sampled signals. For each signal in our sample, we created two plots: an OHLC plot and a line graph. Thus, we made 80800 plots.\n",
    "\n",
    "We created the plots for the technical indicators and save them locally. Next, we send the files to the AWS bucket and delete the local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22714/3325128085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_sampled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'macd_buy_sampled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'macd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'plots/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_h2o_del_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"plots/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/macd_buy_line.parquet.gzip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_sampled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'macd_buy_sampled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'macd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'plots/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'candle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/image-classification-for-technical-indicators/source/plots.py\u001b[0m in \u001b[0;36mbuild_h2o_del_dir\u001b[0;34m(dir_path, signal, save_path)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mh2o_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fastparquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m         return to_parquet(\n\u001b[0m\u001b[1;32m   2678\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mpartition_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFilePathOrBuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mPyArrowImpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fastparquet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFastParquetImpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"engine must be one of 'pyarrow', 'fastparquet'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# since pandas is a dependency of fastparquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# we need to import on first use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         fastparquet = import_optional_dependency(\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0;34m\"fastparquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fastparquet is required for parquet support.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# macd, buy\n",
    "macd_buy_sampled_indices = df[df[\"macd_buy\"] == 1.0].pipe(plots.check_signals,'firm','macd_buy',1.0,20).groupby('firm').sample(20, random_state=748574).index\n",
    "df['macd_buy_sampled'] = [True if x in macd_buy_sampled_indices else False for x in df.index]        \n",
    "\n",
    "plots.plot_sampled(df, 'macd_buy_sampled', 'macd', 'buy', 26, 'plots/', 'close', 'line')\n",
    "plots.build_h2o_del_dir(\"plots/\", 1, \"data/macd_buy_line.parquet.gzip\", True)\n",
    "\n",
    "plots.plot_sampled(df, 'macd_buy_sampled', 'macd', 'buy', 26, 'plots/', 'close', 'candle')\n",
    "plots.build_h2o_del_dir(\"plots/\", 1, \"data/macd_buy_candle.parquet.gzip\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macd, no buy\n",
    "macd_nobuy_sampled_indices = df[df[\"macd_buy\"] == 0.0].pipe(plots.check_signals,'firm','macd_buy',0.0,20).groupby('firm').sample(20, random_state=748574).index\n",
    "df['macd_nobuy_sampled'] = [True if x in macd_nobuy_sampled_indices else False for x in df.index]\n",
    "\n",
    "plots.plot_sampled(df, 'macd_nobuy_sampled', 'macd','nobuy',  26, 'plots/', 'close', 'line')\n",
    "plots.build_h2o_del_dir(\"plots/\", 0, \"data/macd_nobuy_line.parquet.gzip\", True)\n",
    "\n",
    "plots.plot_sampled(df, 'macd_nobuy_sampled', 'macd', 'nobuy', 26, 'plots/','close', 'candle')\n",
    "plots.build_h2o_del_dir(\"plots/\", 0, \"data/macd_nobuy_line.parquet.gzip\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bb, buy\n",
    "bb_buy_sampled_indices = df[df[\"bb_buy\"] == 1.0].pipe(plots.check_signals,'firm','bb_buy',1.0,20).groupby('firm').sample(20, random_state=9224279).index\n",
    "df['bb_buy_sampled'] = [True if x in bb_buy_sampled_indices else False for x in df.index]  \n",
    "\n",
    "plots.plot_sampled(df, 'bb_buy_sampled', 'bb', 'buy', 20, 'plots/', 'close', 'line')\n",
    "plots.build_h2o_del_dir(\"plots/\", 1, \"data/bb_buy_line.parquet.gzip\", True)\n",
    "\n",
    "plots.plot_sampled(df, 'bb_buy_sampled', 'bb', 'buy', 20, 'plots/', 'close', 'candle')\n",
    "plots.build_h2o_del_dir(\"plots/\", 1, \"data/bb_buy_candle.parquet.gzip\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_nobuy_sampled_indices = df[df[\"bb_buy\"] == 0.0].pipe(plots.check_signals,'firm','bb_buy',0.0,20).groupby('firm').sample(20, random_state=9224279).index\n",
    "df['bb_nobuy_sampled'] = [True if x in bb_nobuy_sampled_indices else False for x in df.index]\n",
    "\n",
    "plots.plot_sampled(df, 'bb_nobuy_sampled', 'bb', 'nobuy', 20, 'plots/', 'close', 'line')\n",
    "plots.build_h2o_del_dir(\"plots/\", 0, \"data/bb_nobuy_line.parquet.gzip\", True)\n",
    "\n",
    "plots.plot_sampled(df, 'bb_nobuy_sampled', 'bb', 'nobuy', 20, 'plots/', 'close', 'candle')\n",
    "plots.build_h2o_del_dir(\"plots/\", 0, \"data/bb_nobuy_candle.parquet.gzip\", True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
